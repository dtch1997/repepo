{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Example in Pythia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, pipeline, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "\n",
    "CACHE_DIR = \"/home/daniel/.huggingface/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"EleutherAI/pythia-70m\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, device_map=\"auto\", cache_dir=CACHE_DIR)\n",
    "use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False, cache_dir=CACHE_DIR)\n",
    "tokenizer.pad_token_id = 0 \n",
    "# clear the gpu memory\n",
    "torch.cuda.empty_cache()\n",
    "model.to(torch.device(\"cuda\"))\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 512)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Supervised Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Iterable\n",
    "import numpy as np\n",
    "\n",
    "PromptResponseDataset = Iterable[Dict[str, str]]\n",
    "\n",
    "def sanity_check_prompt_response_dataset(dataset: PromptResponseDataset):\n",
    "    indexes = np.random.randint(0, len(dataset), 10)\n",
    "    for idx in indexes:\n",
    "        idx = int(idx)\n",
    "        data = dataset[idx]\n",
    "        assert \"prompt\" in data\n",
    "        assert \"response\" in data\n",
    "        assert isinstance(data[\"prompt\"], str)\n",
    "        assert isinstance(data[\"response\"], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"truthful_qa\", \"generation\")[\"validation\"]\n",
    "# Make it into prompt-response format\n",
    "dataset = dataset.map(lambda x: {'prompt': x['question'], 'response': x['best_answer']})\n",
    "sanity_check_prompt_response_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['type', 'category', 'question', 'best_answer', 'correct_answers', 'incorrect_answers', 'source', 'prompt', 'response'],\n",
       "    num_rows: 817\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n"
     ]
    }
   ],
   "source": [
    "# Print the max length of prompt + response\n",
    "def get_max_length(dataset: PromptResponseDataset):\n",
    "    # Get the max length of prompt + response\n",
    "    max_length = 0\n",
    "    for i in range(len(dataset)):\n",
    "        prompt, response = dataset[i]['prompt'], dataset[i]['response']\n",
    "        max_length = max(max_length, len(prompt) + len(response))\n",
    "        \n",
    "    return max_length\n",
    "\n",
    "print(get_max_length(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: May need to truncate if SFT exceeds context length? \n",
    "# I'm not gonna worry about this for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happens to you if you eat watermelon seeds?\n",
      "The watermelon seeds pass through your digestive system\n",
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "20\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    example = dataset[i]\n",
    "    print(example[\"prompt\"])\n",
    "    print(example[\"response\"])\n",
    "    output = tokenizer(example[\"prompt\"], example[\"response\"])\n",
    "    print(output.keys())\n",
    "    tokens = output['input_ids']\n",
    "    masks = output['attention_mask']\n",
    "    print(len(tokens))\n",
    "    print(masks)\n",
    "    # for token in tokens:\n",
    "    #     print(tokenizer.decode(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"prompt\"], \n",
    "        examples[\"response\"]\n",
    "    )\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "orig_col_names = dataset.column_names\n",
    "# datasets = DatasetDict({'train': dataset})\n",
    "train_dataset = dataset.map(\n",
    "    prepare_train_features, \n",
    "    batched=True, \n",
    "    remove_columns=orig_col_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817\n",
      "20\n",
      "14\n",
      "20\n",
      "24\n",
      "28\n",
      "21\n",
      "22\n",
      "39\n",
      "24\n",
      "19\n",
      "23\n",
      "18\n",
      "34\n",
      "25\n",
      "32\n",
      "34\n",
      "28\n",
      "23\n",
      "19\n",
      "17\n",
      "26\n",
      "40\n",
      "23\n",
      "28\n",
      "28\n",
      "24\n",
      "30\n",
      "25\n",
      "30\n",
      "29\n",
      "31\n",
      "20\n",
      "16\n",
      "16\n",
      "28\n",
      "16\n",
      "15\n",
      "19\n",
      "19\n",
      "24\n",
      "27\n",
      "17\n",
      "18\n",
      "20\n",
      "24\n",
      "21\n",
      "27\n",
      "26\n",
      "30\n",
      "29\n",
      "23\n",
      "35\n",
      "20\n",
      "13\n",
      "28\n",
      "22\n",
      "20\n",
      "15\n",
      "19\n",
      "32\n",
      "19\n",
      "16\n",
      "35\n",
      "16\n",
      "25\n",
      "24\n",
      "24\n",
      "12\n",
      "23\n",
      "17\n",
      "14\n",
      "19\n",
      "18\n",
      "23\n",
      "36\n",
      "25\n",
      "15\n",
      "21\n",
      "31\n",
      "19\n",
      "18\n",
      "22\n",
      "21\n",
      "17\n",
      "21\n",
      "18\n",
      "15\n",
      "15\n",
      "18\n",
      "14\n",
      "24\n",
      "25\n",
      "23\n",
      "23\n",
      "16\n",
      "21\n",
      "23\n",
      "18\n",
      "16\n",
      "26\n",
      "13\n",
      "12\n",
      "17\n",
      "13\n",
      "15\n",
      "18\n",
      "19\n",
      "9\n",
      "17\n",
      "11\n",
      "14\n",
      "14\n",
      "11\n",
      "25\n",
      "13\n",
      "16\n",
      "20\n",
      "19\n",
      "15\n",
      "17\n",
      "15\n",
      "17\n",
      "12\n",
      "17\n",
      "13\n",
      "15\n",
      "39\n",
      "19\n",
      "45\n",
      "37\n",
      "37\n",
      "30\n",
      "49\n",
      "26\n",
      "36\n",
      "52\n",
      "19\n",
      "17\n",
      "25\n",
      "19\n",
      "18\n",
      "21\n",
      "23\n",
      "15\n",
      "25\n",
      "21\n",
      "16\n",
      "15\n",
      "20\n",
      "20\n",
      "15\n",
      "15\n",
      "27\n",
      "20\n",
      "17\n",
      "16\n",
      "20\n",
      "17\n",
      "16\n",
      "18\n",
      "11\n",
      "11\n",
      "21\n",
      "12\n",
      "11\n",
      "11\n",
      "15\n",
      "28\n",
      "17\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "21\n",
      "21\n",
      "20\n",
      "29\n",
      "20\n",
      "14\n",
      "18\n",
      "18\n",
      "23\n",
      "31\n",
      "32\n",
      "20\n",
      "31\n",
      "26\n",
      "34\n",
      "35\n",
      "30\n",
      "30\n",
      "31\n",
      "31\n",
      "29\n",
      "22\n",
      "21\n",
      "24\n",
      "15\n",
      "13\n",
      "14\n",
      "25\n",
      "30\n",
      "22\n",
      "28\n",
      "19\n",
      "15\n",
      "13\n",
      "14\n",
      "17\n",
      "27\n",
      "19\n",
      "30\n",
      "33\n",
      "23\n",
      "27\n",
      "22\n",
      "21\n",
      "23\n",
      "29\n",
      "27\n",
      "17\n",
      "25\n",
      "14\n",
      "19\n",
      "19\n",
      "23\n",
      "34\n",
      "19\n",
      "20\n",
      "18\n",
      "16\n",
      "21\n",
      "18\n",
      "23\n",
      "25\n",
      "16\n",
      "19\n",
      "35\n",
      "16\n",
      "19\n",
      "27\n",
      "18\n",
      "23\n",
      "32\n",
      "18\n",
      "15\n",
      "23\n",
      "30\n",
      "30\n",
      "33\n",
      "27\n",
      "26\n",
      "29\n",
      "20\n",
      "26\n",
      "42\n",
      "25\n",
      "18\n",
      "21\n",
      "14\n",
      "12\n",
      "22\n",
      "9\n",
      "35\n",
      "18\n",
      "21\n",
      "20\n",
      "12\n",
      "29\n",
      "19\n",
      "27\n",
      "27\n",
      "38\n",
      "19\n",
      "25\n",
      "38\n",
      "16\n",
      "29\n",
      "59\n",
      "27\n",
      "18\n",
      "17\n",
      "24\n",
      "29\n",
      "26\n",
      "29\n",
      "20\n",
      "29\n",
      "25\n",
      "30\n",
      "18\n",
      "19\n",
      "23\n",
      "17\n",
      "27\n",
      "31\n",
      "33\n",
      "34\n",
      "41\n",
      "30\n",
      "21\n",
      "23\n",
      "27\n",
      "24\n",
      "19\n",
      "22\n",
      "24\n",
      "18\n",
      "22\n",
      "24\n",
      "21\n",
      "18\n",
      "22\n",
      "20\n",
      "29\n",
      "20\n",
      "22\n",
      "17\n",
      "25\n",
      "22\n",
      "22\n",
      "17\n",
      "21\n",
      "17\n",
      "18\n",
      "20\n",
      "15\n",
      "19\n",
      "20\n",
      "25\n",
      "21\n",
      "20\n",
      "20\n",
      "23\n",
      "23\n",
      "21\n",
      "19\n",
      "21\n",
      "24\n",
      "33\n",
      "14\n",
      "15\n",
      "18\n",
      "24\n",
      "31\n",
      "16\n",
      "22\n",
      "15\n",
      "30\n",
      "22\n",
      "23\n",
      "25\n",
      "18\n",
      "21\n",
      "23\n",
      "18\n",
      "26\n",
      "25\n",
      "25\n",
      "24\n",
      "18\n",
      "23\n",
      "26\n",
      "26\n",
      "35\n",
      "32\n",
      "21\n",
      "22\n",
      "15\n",
      "27\n",
      "29\n",
      "24\n",
      "17\n",
      "24\n",
      "17\n",
      "22\n",
      "23\n",
      "19\n",
      "20\n",
      "19\n",
      "19\n",
      "19\n",
      "33\n",
      "30\n",
      "21\n",
      "31\n",
      "30\n",
      "21\n",
      "20\n",
      "28\n",
      "29\n",
      "28\n",
      "31\n",
      "24\n",
      "22\n",
      "26\n",
      "33\n",
      "18\n",
      "26\n",
      "17\n",
      "16\n",
      "21\n",
      "21\n",
      "23\n",
      "20\n",
      "24\n",
      "23\n",
      "26\n",
      "29\n",
      "20\n",
      "25\n",
      "23\n",
      "22\n",
      "20\n",
      "20\n",
      "25\n",
      "23\n",
      "19\n",
      "26\n",
      "25\n",
      "31\n",
      "23\n",
      "34\n",
      "36\n",
      "28\n",
      "33\n",
      "39\n",
      "39\n",
      "41\n",
      "29\n",
      "38\n",
      "34\n",
      "49\n",
      "49\n",
      "40\n",
      "49\n",
      "32\n",
      "48\n",
      "41\n",
      "37\n",
      "32\n",
      "34\n",
      "40\n",
      "30\n",
      "27\n",
      "26\n",
      "29\n",
      "17\n",
      "33\n",
      "26\n",
      "22\n",
      "16\n",
      "16\n",
      "20\n",
      "16\n",
      "19\n",
      "21\n",
      "23\n",
      "20\n",
      "22\n",
      "29\n",
      "29\n",
      "24\n",
      "31\n",
      "23\n",
      "28\n",
      "31\n",
      "20\n",
      "31\n",
      "27\n",
      "32\n",
      "29\n",
      "32\n",
      "20\n",
      "19\n",
      "15\n",
      "31\n",
      "38\n",
      "29\n",
      "27\n",
      "31\n",
      "31\n",
      "22\n",
      "28\n",
      "31\n",
      "24\n",
      "29\n",
      "15\n",
      "26\n",
      "32\n",
      "22\n",
      "31\n",
      "28\n",
      "29\n",
      "26\n",
      "18\n",
      "16\n",
      "26\n",
      "24\n",
      "22\n",
      "24\n",
      "16\n",
      "31\n",
      "26\n",
      "26\n",
      "32\n",
      "19\n",
      "24\n",
      "37\n",
      "34\n",
      "33\n",
      "32\n",
      "45\n",
      "43\n",
      "23\n",
      "27\n",
      "27\n",
      "19\n",
      "21\n",
      "29\n",
      "28\n",
      "30\n",
      "29\n",
      "18\n",
      "18\n",
      "17\n",
      "20\n",
      "19\n",
      "23\n",
      "18\n",
      "32\n",
      "30\n",
      "38\n",
      "38\n",
      "39\n",
      "18\n",
      "21\n",
      "17\n",
      "18\n",
      "28\n",
      "38\n",
      "22\n",
      "17\n",
      "23\n",
      "15\n",
      "22\n",
      "38\n",
      "29\n",
      "29\n",
      "23\n",
      "23\n",
      "29\n",
      "30\n",
      "25\n",
      "25\n",
      "23\n",
      "29\n",
      "22\n",
      "38\n",
      "48\n",
      "28\n",
      "34\n",
      "36\n",
      "37\n",
      "37\n",
      "30\n",
      "33\n",
      "35\n",
      "38\n",
      "43\n",
      "38\n",
      "44\n",
      "64\n",
      "56\n",
      "59\n",
      "63\n",
      "20\n",
      "24\n",
      "20\n",
      "21\n",
      "24\n",
      "18\n",
      "19\n",
      "15\n",
      "19\n",
      "22\n",
      "15\n",
      "14\n",
      "18\n",
      "23\n",
      "23\n",
      "20\n",
      "25\n",
      "17\n",
      "16\n",
      "18\n",
      "28\n",
      "20\n",
      "17\n",
      "16\n",
      "18\n",
      "21\n",
      "31\n",
      "22\n",
      "23\n",
      "24\n",
      "29\n",
      "26\n",
      "22\n",
      "23\n",
      "19\n",
      "12\n",
      "19\n",
      "15\n",
      "18\n",
      "16\n",
      "17\n",
      "16\n",
      "12\n",
      "12\n",
      "11\n",
      "14\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "17\n",
      "20\n",
      "28\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "14\n",
      "14\n",
      "28\n",
      "28\n",
      "18\n",
      "18\n",
      "24\n",
      "24\n",
      "17\n",
      "13\n",
      "36\n",
      "27\n",
      "21\n",
      "12\n",
      "14\n",
      "14\n",
      "19\n",
      "26\n",
      "25\n",
      "19\n",
      "15\n",
      "18\n",
      "23\n",
      "21\n",
      "27\n",
      "19\n",
      "18\n",
      "22\n",
      "22\n",
      "23\n",
      "15\n",
      "19\n",
      "23\n",
      "18\n",
      "43\n",
      "29\n",
      "19\n",
      "29\n",
      "24\n",
      "29\n",
      "18\n",
      "32\n",
      "18\n",
      "25\n",
      "17\n",
      "23\n",
      "18\n",
      "18\n",
      "30\n",
      "26\n",
      "22\n",
      "24\n",
      "16\n",
      "24\n",
      "29\n",
      "26\n",
      "19\n",
      "21\n",
      "19\n",
      "21\n",
      "22\n",
      "27\n",
      "27\n",
      "15\n",
      "26\n",
      "24\n",
      "34\n",
      "41\n",
      "45\n",
      "22\n",
      "27\n",
      "29\n",
      "27\n",
      "11\n",
      "15\n",
      "16\n",
      "14\n",
      "23\n",
      "22\n",
      "27\n",
      "21\n",
      "27\n",
      "33\n",
      "53\n",
      "16\n",
      "21\n",
      "33\n",
      "34\n",
      "22\n",
      "37\n",
      "31\n",
      "17\n",
      "20\n",
      "23\n",
      "24\n",
      "12\n",
      "17\n",
      "20\n",
      "21\n",
      "12\n",
      "30\n",
      "24\n",
      "27\n",
      "31\n",
      "23\n",
      "18\n",
      "17\n",
      "25\n",
      "14\n",
      "17\n",
      "23\n",
      "13\n",
      "17\n",
      "22\n",
      "26\n",
      "24\n",
      "16\n",
      "22\n",
      "25\n",
      "20\n",
      "20\n",
      "37\n",
      "26\n",
      "18\n",
      "29\n",
      "29\n",
      "18\n",
      "18\n",
      "33\n",
      "25\n",
      "18\n",
      "15\n",
      "31\n",
      "23\n",
      "16\n",
      "21\n",
      "18\n",
      "19\n",
      "27\n",
      "15\n",
      "12\n",
      "19\n",
      "24\n",
      "21\n",
      "15\n",
      "23\n",
      "26\n",
      "23\n",
      "23\n",
      "18\n",
      "25\n",
      "22\n",
      "21\n",
      "20\n",
      "17\n",
      "18\n",
      "31\n",
      "20\n",
      "15\n",
      "21\n",
      "14\n",
      "17\n",
      "35\n",
      "21\n",
      "25\n",
      "25\n",
      "19\n",
      "23\n",
      "29\n",
      "23\n",
      "29\n",
      "30\n",
      "18\n",
      "13\n",
      "11\n",
      "11\n",
      "16\n",
      "16\n",
      "45\n",
      "45\n",
      "26\n",
      "21\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "for example in train_dataset:\n",
    "    print(len(example['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "batch_size = 128\n",
    "args = TrainingArguments(\n",
    "    f\"test\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_steps = 100,\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer, mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.420777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.333539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.486226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.698187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.863887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.940004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.987640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.989979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.980610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=70, training_loss=6.442421613420759, metrics={'train_runtime': 15.323, 'train_samples_per_second': 533.185, 'train_steps_per_second': 4.568, 'total_flos': 119698203082752.0, 'train_loss': 6.442421613420759, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "\n",
    "We're just going to evaluate the model on the same dataset it was trained on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repepo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
