{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualize Dataset-level Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/ml_workspace/datasets\n",
      "Number of datasets:  135\n"
     ]
    }
   ],
   "source": [
    "from repepo.data.make_dataset import list_datasets\n",
    "from repepo.experiments_2.utils.config import DATASET_DIR\n",
    "\n",
    "print(DATASET_DIR)\n",
    "datasets = list_datasets(DATASET_DIR)\n",
    "print(\"Number of datasets: \", len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repepo.experiments_2.utils.helpers import (\n",
    "    ConceptVectorsConfig,\n",
    "    load_activation_differences\n",
    ")\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    continue\n",
    "    # TODO\n",
    "    config = ConceptVectorsConfig()\n",
    "    config.train_dataset_spec.name = dataset_name \n",
    "    difference_vectors = load_activation_differences(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Individual Concept Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def run_pca(data: np.ndarray, n_components: int = 1):\n",
    "    \"\"\"\n",
    "    Run PCA on a batch of N x D vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - data: N x D array where N is the number of samples and D is the number of features.\n",
    "\n",
    "    Returns:\n",
    "    - principal_components: Principal components obtained from PCA.\n",
    "    - explained_variance: Explained variance corresponding to each principal component.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    coefficients = pca.fit_transform(data)\n",
    "    components = pca.components_\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "    return components, explained_variance\n",
    "\n",
    "def get_component_and_variance(\n",
    "    config: ConceptVectorsConfig,\n",
    "    layer: int,\n",
    "    n_components: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Get the principal components and explained variance of the activation differences at a given layer.\n",
    "\n",
    "    Parameters:\n",
    "    - config: Configuration object containing the dataset name and other parameters.\n",
    "    - layer: Layer index for which to obtain the principal components and explained variance.\n",
    "\n",
    "    Returns:\n",
    "    - principal_components: Principal components obtained from PCA.\n",
    "    - explained_variance: Explained variance corresponding to each principal component.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load activation differences\n",
    "    activation_differences = load_activation_differences(config)\n",
    "\n",
    "    # Convert to numpy\n",
    "    activation_differences_np = torch.stack(activation_differences[layer]).numpy()\n",
    "\n",
    "    # Run PCA\n",
    "    principal_components, explained_variance = run_pca(\n",
    "        activation_differences_np, n_components=n_components\n",
    "    )\n",
    "\n",
    "    return principal_components, explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repepo.data.make_dataset import DatasetSpec\n",
    "\n",
    "datasets = [\n",
    "    \"truthfulqa\",\n",
    "    \"subscribes-to-virtue-ethics\",\n",
    "    \"interest-in-math\",\n",
    "    \"anti-immigration\",\n",
    "    \"has-disability\"\n",
    "]\n",
    "\n",
    "tqa_config = ConceptVectorsConfig(\n",
    "    train_dataset_spec = (\n",
    "        DatasetSpec(\n",
    "            name = \"truthfulqa\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "ethics_config = ConceptVectorsConfig(\n",
    "    train_dataset_spec = (\n",
    "        DatasetSpec(\n",
    "            name = \"subscribes-to-virtue-ethics\",\n",
    "            split=\":1%\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "math_config = ConceptVectorsConfig(\n",
    "    train_dataset_spec = (\n",
    "        DatasetSpec(\n",
    "            name = \"interest-in-math\",\n",
    "            split=\":1%\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5120)\n",
      "[0.50660064]\n"
     ]
    }
   ],
   "source": [
    "tqa_components, tqa_variance = get_component_and_variance(\n",
    "    tqa_config, 13\n",
    ")\n",
    "print(tqa_components.shape)\n",
    "print(tqa_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0 | cos_sim: 1.00 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 1 | cos_sim: 1.00 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 2 | cos_sim: 1.00 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 3 | cos_sim: 0.99 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 4 | cos_sim: 0.99 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 5 | cos_sim: 0.99 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 6 | cos_sim: 0.99 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 7 | cos_sim: 0.99 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 8 | cos_sim: 0.99 | var_ethics: 1.00 | var_math: 1.00\n",
      "layer: 9 | cos_sim: 0.99 | var_ethics: 0.99 | var_math: 1.00\n",
      "layer: 10 | cos_sim: 0.99 | var_ethics: 0.99 | var_math: 0.99\n",
      "layer: 11 | cos_sim: 0.99 | var_ethics: 0.99 | var_math: 0.99\n",
      "layer: 12 | cos_sim: 0.99 | var_ethics: 0.99 | var_math: 0.99\n",
      "layer: 13 | cos_sim: 0.98 | var_ethics: 0.98 | var_math: 0.98\n",
      "layer: 14 | cos_sim: 0.98 | var_ethics: 0.97 | var_math: 0.98\n",
      "layer: 15 | cos_sim: 0.98 | var_ethics: 0.97 | var_math: 0.98\n",
      "layer: 16 | cos_sim: 0.98 | var_ethics: 0.97 | var_math: 0.97\n",
      "layer: 17 | cos_sim: 0.97 | var_ethics: 0.96 | var_math: 0.97\n",
      "layer: 18 | cos_sim: 0.97 | var_ethics: 0.95 | var_math: 0.96\n",
      "layer: 19 | cos_sim: 0.97 | var_ethics: 0.95 | var_math: 0.96\n",
      "layer: 20 | cos_sim: 0.98 | var_ethics: 0.95 | var_math: 0.96\n",
      "layer: 21 | cos_sim: 0.97 | var_ethics: 0.94 | var_math: 0.96\n",
      "layer: 22 | cos_sim: 0.97 | var_ethics: 0.94 | var_math: 0.96\n",
      "layer: 23 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 24 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 25 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 26 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 27 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 28 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 29 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 30 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 31 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 32 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 33 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 34 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 35 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 36 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 37 | cos_sim: 0.98 | var_ethics: 0.93 | var_math: 0.95\n",
      "layer: 38 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.94\n",
      "layer: 39 | cos_sim: 0.97 | var_ethics: 0.93 | var_math: 0.94\n"
     ]
    }
   ],
   "source": [
    "for layer in range(40):\n",
    "    ethics_components, ethics_variance = get_component_and_variance(ethics_config, layer)\n",
    "    math_components, math_variance = get_component_and_variance(math_config, layer)\n",
    "    \n",
    "    # Cosine similarity between the principal components\n",
    "    cosine_sim = np.dot(ethics_components, math_components.T)\n",
    "    results_str = f\"layer: {layer} | cos_sim: {cosine_sim[0, 0]:.2f} | var_ethics: {ethics_variance[0]:.2f} | var_math: {math_variance[0]:.2f}\"\n",
    "    print(results_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repepo-GhatvsUS-repepo-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
