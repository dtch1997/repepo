{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WORK_DIR = /home/daniel/ml_workspace/repepo/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repepo.steering.run_experiment import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from repepo.steering.utils.helpers import SteeringConfig, EmptyTorchCUDACache\n",
    "from repepo.steering.sweeps.constants import ALL_TOKEN_CONCEPT_DATASETS, ALL_LLAMA_7B_LAYERS, ALL_MULTIPLIERS\n",
    "from repepo.steering.sweeps.configs import get_abstract_concept_config\n",
    "\n",
    "datasets = [\"power-seeking-inclination\"]\n",
    "layers = [13]\n",
    "multipliers = [-1, 0, 1]\n",
    "train_splits = [\"0%:+1\", \"0%:+3\", \"0%:+10\", \"0%:+30\", \"0%:+100\"]\n",
    "test_splits = [\"40%:+10\"]\n",
    "\n",
    "def iter_config():\n",
    "    for dataset, layer, multiplier, train_split, test_split in itertools.product(datasets, layers, multipliers, train_splits, test_splits):\n",
    "        yield SteeringConfig(\n",
    "            train_dataset=dataset,\n",
    "            train_split=train_split,\n",
    "            formatter=\"llama-chat-formatter\",\n",
    "            layer=layer,\n",
    "            multiplier=multiplier,\n",
    "            test_dataset=dataset,\n",
    "            test_split=test_split,\n",
    "            test_completion_template=\"{prompt} My answer is: {response}\",\n",
    "            patch_generation_tokens_only=True,\n",
    "            skip_first_n_generation_tokens=1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repepo.steering.run_sweep import run_sweep, load_sweep_results\n",
    "\n",
    "RUN = False\n",
    "configs = list(iter_config())\n",
    "\n",
    "if RUN:\n",
    "    run_sweep(configs)\n",
    "\n",
    "results = load_sweep_results(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "rows = []\n",
    "for config, result in results:\n",
    "    row = asdict(config)\n",
    "    row.update(**{\n",
    "        \"test_positive_example\": result.predictions[0].positive_output_prob.text,\n",
    "        \"test_negative_example\": result.predictions[0].negative_output_prob.text,\n",
    "        \"mean_logit_diff\": result.metrics['mean_logit_diff'],\n",
    "    })\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize important dataset metadata\n",
    "train_fields = ['model_name', 'train_dataset', 'train_split', 'train_completion_template', 'formatter', 'aggregator', 'layer', 'layer_type']\n",
    "df[train_fields].drop_duplicates()\n",
    "\n",
    "# Display without index\n",
    "from IPython.display import HTML\n",
    "HTML(df[train_fields].drop_duplicates().to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group results by all training fields:\n",
    "# - train_dataset, train_split, train_completion_template, formatter, aggregator, layer, layer type\n",
    "train_fields = ['train_dataset', 'train_split', 'train_completion_template', 'formatter', 'aggregator', 'layer', 'layer_type']\n",
    "grouped = df.groupby(train_fields)\n",
    "\n",
    "# Fit a linear model of (mean logit diff) vs (multiplier)\n",
    "import numpy as np\n",
    "def compute_steering_efficiency(row):\n",
    "    x = row.multiplier\n",
    "    y = row.mean_logit_diff\n",
    "    (slope, _), res, rank, sv, rcond = np.polyfit(x, y, 1, full=True)\n",
    "    return pd.Series({'steering_efficiency': slope, 'residuals': np.sqrt(res).item()})\n",
    "\n",
    "steering_efficiency_df = grouped.apply(compute_steering_efficiency)\n",
    "# merge back into original df\n",
    "df = df.merge(steering_efficiency_df, left_on=train_fields, right_index=True)\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename train_split to be more readable\n",
    "df['train_sample_size'] = df['train_split'].str.replace('0%:+', '')\n",
    "\n",
    "# Plot mean logit diff vs multiplier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.lineplot(data=df, x='multiplier', y='mean_logit_diff', hue='train_sample_size')\n",
    "ax.set_title('Mean logit diff vs multiplier for different train sample sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only dataset name, layer, and steering efficiency\n",
    "data_df = df[['train_dataset', 'train_sample_size', 'layer', 'steering_efficiency']]\n",
    "data_df = data_df.drop_duplicates()\n",
    "print(len(data_df))\n",
    "\n",
    "# Bar plot of steering efficiency vs train split\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=\"train_sample_size\", y=\"steering_efficiency\", data=data_df)\n",
    "ax.set_title(\"Steering efficiency vs train_sample_size\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute sample-level steering metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "rows = []\n",
    "for config, result in results:\n",
    "    partial_row = asdict(config)\n",
    "    for prediction in result.predictions:\n",
    "        row = partial_row.copy()\n",
    "        row.update(**{\n",
    "            \"test_positive_example\": prediction.positive_output_prob.text,\n",
    "            \"test_negative_example\": prediction.negative_output_prob.text,\n",
    "            \"logit_diff\": prediction.metrics['logit_diff'],\n",
    "        })\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test examples. \n",
    "temp_df = df[['test_positive_example', 'test_negative_example']].drop_duplicates()\n",
    "print(len(temp_df))\n",
    "HTML(\n",
    "    temp_df.to_html(index=False)\n",
    "    # View newlines.\n",
    "    .replace(\"\\\\n\",\"<br>\")\n",
    "    # Left align text.\n",
    "    .replace('<td>', '<td align=\"left\">')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compare the logit diff of a single example, for the same steering vector, at different multipliers\n",
    "# 'The same steering vector' is determined by the train fields. \n",
    "grouped_df = df.groupby(train_fields + ['test_positive_example', 'test_negative_example'])\n",
    "\n",
    "# Print one group\n",
    "grouped_df.get_group((list(grouped_df.groups)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steering_efficiency(row):\n",
    "    x = row.multiplier\n",
    "    y = row.logit_diff\n",
    "    (slope, _), res, rank, sv, rcond = np.polyfit(x, y, 1, full=True)\n",
    "    return pd.Series({'steering_efficiency': slope, 'residuals': np.sqrt(res).item()})\n",
    "\n",
    "# Apply 'compute steering efficiency'\n",
    "steering_efficiency_df = grouped_df.apply(compute_steering_efficiency)\n",
    "\n",
    "# merge back into original df\n",
    "df = df.merge(steering_efficiency_df, left_on=train_fields + ['test_positive_example', 'test_negative_example'], right_index=True)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[['train_split', 'test_positive_example', 'test_negative_example', 'multiplier', 'logit_diff', 'steering_efficiency']].drop_duplicates()\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full examples are too long, so just assign an integer per example\n",
    "df['test_index'] = df.test_positive_example.astype('category').cat.codes.astype(str)\n",
    "# Filter by the 1-sample train split\n",
    "temp_df = df[df.train_split == \"0%:+1\"]\n",
    "temp_df = temp_df.sort_values('test_index')\n",
    "print(len(temp_df))\n",
    "# Print the number of unique indices\n",
    "print(len(temp_df.test_index.unique()))\n",
    "\n",
    "# Plot mean logit diff vs multiplier across all examples\n",
    "# Use the seaborn objects interface\n",
    "import seaborn.objects as so\n",
    "p = (\n",
    "    so.Plot(temp_df, x='multiplier', y='logit_diff')\n",
    "    .add(so.Line(), color='test_index')\n",
    ")\n",
    "p.label(\n",
    "    title = \"Per-example logit diff vs multiplier, using the 1-sample train split\",\n",
    "    color = 'Test example index'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by the 1-sample train split\n",
    "temp_df = df[df.train_split == \"0%:+100\"]\n",
    "temp_df = temp_df.sort_values('test_index')\n",
    "print(len(temp_df))\n",
    "# Print the number of unique indices\n",
    "print(len(temp_df.test_index.unique()))\n",
    "\n",
    "# Plot mean logit diff vs multiplier across all examples\n",
    "# Use the seaborn objects interface\n",
    "import seaborn.objects as so\n",
    "p = (\n",
    "    so.Plot(temp_df, x='multiplier', y='logit_diff')\n",
    "    .add(so.Line(), color='test_index')\n",
    ")\n",
    "p.label(\n",
    "    title = \"Per-example logit diff vs multiplier, using the 100-sample train split\",\n",
    "    color = 'Test example index'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
