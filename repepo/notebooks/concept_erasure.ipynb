{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if concept erasure can eliminate A-B token bias from the steering vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a316c49067c44f3a57a1ae89ff9597d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from repepo.core.types import Example, Completion\n",
    "from repepo.core.format import LlamaChatFormatter\n",
    "from repepo.core.pipeline import Pipeline\n",
    "from steering_vectors import train_steering_vector\n",
    "from repepo.steering.utils.helpers import get_model_and_tokenizer\n",
    "from repepo.steering.build_steering_training_data import (\n",
    "    build_steering_vector_training_data\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    Example(\n",
    "        positive = Completion(\n",
    "            prompt = \"(\",\n",
    "            response = \"A)\"\n",
    "        ),\n",
    "        negative = Completion(\n",
    "            prompt = \"(\",\n",
    "            response = \"B)\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer(\"meta-llama/Llama-2-7b-chat-hf\", load_in_8bit=True)\n",
    "formatter = LlamaChatFormatter()\n",
    "pipeline = Pipeline(model, tokenizer, formatter)\n",
    "steering_vector_training_data = build_steering_vector_training_data(\n",
    "    pipeline, train_dataset\n",
    ")\n",
    "layer = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training steering vector: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "ab_steering_vector = train_steering_vector(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    steering_vector_training_data,\n",
    "    layers=[layer],\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SteeringVector(layer_activations={13: tensor([-0.0631, -0.2588,  0.1665,  ..., -0.3843,  0.0649, -0.2756],\n",
       "       device='cuda:0', dtype=torch.float16)}, layer_type='decoder_block')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_steering_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_prob</th>\n",
       "      <th>logit_diff</th>\n",
       "      <th>test_example.positive.text</th>\n",
       "      <th>test_example.negative.text</th>\n",
       "      <th>test_example.idx</th>\n",
       "      <th>multiplier</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>steering_label</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>slope</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005577</td>\n",
       "      <td>-5.593750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>politically-conservative</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.816964</td>\n",
       "      <td>0.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.020646</td>\n",
       "      <td>-6.468750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>politically-conservative</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.551374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.976483</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>politically-conservative</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>-0.541295</td>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.006772</td>\n",
       "      <td>-5.617188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>politically-conservative</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.953683</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.110541</td>\n",
       "      <td>-2.265625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>politically-conservative</td>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.016462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pos_prob  logit_diff test_example.positive.text  \\\n",
       "0    0.005577   -5.593750                        NaN   \n",
       "49   0.020646   -6.468750                        NaN   \n",
       "98   0.976483    5.500000                        NaN   \n",
       "147  0.006772   -5.617188                        NaN   \n",
       "196  0.110541   -2.265625                        NaN   \n",
       "\n",
       "    test_example.negative.text  test_example.idx  multiplier  \\\n",
       "0                          NaN                 0        -1.5   \n",
       "49                         NaN                 1        -1.5   \n",
       "98                         NaN                 2        -1.5   \n",
       "147                        NaN                 3        -1.5   \n",
       "196                        NaN                 4        -1.5   \n",
       "\n",
       "                 dataset_name steering_label dataset_label     slope  residual  \n",
       "0    politically-conservative       baseline      baseline  0.816964  0.000558  \n",
       "49   politically-conservative       baseline      baseline  0.988839  0.551374  \n",
       "98   politically-conservative       baseline      baseline -0.541295  0.132804  \n",
       "147  politically-conservative       baseline      baseline  0.953683  0.001672  \n",
       "196  politically-conservative       baseline      baseline  0.758929  0.016462  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_without_erasure_df = pd.read_csv('../paper/steerability_id_final.csv', index_col = 0, escapechar='\\\\', sep='\\t')\n",
    "results_without_erasure_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate new steering results with erasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "\n",
    "from steering_vectors.aggregators import Aggregator, mean_aggregator\n",
    "from steering_vectors.token_utils import adjust_read_indices_for_padding, fix_pad_token\n",
    "from steering_vectors.utils import batchify\n",
    "\n",
    "from steering_vectors.layer_matching import LayerType, ModelLayerConfig, guess_and_enhance_layer_config\n",
    "from steering_vectors.record_activations import record_activations\n",
    "from steering_vectors.steering_vector import SteeringVector\n",
    "from steering_vectors.train_steering_vector import SteeringVectorTrainingSample, extract_activations, aggregate_activations\n",
    "from concept_erasure import LeaceEraser\n",
    "\n",
    "@torch.no_grad()\n",
    "def train_steering_vector_with_erasure(\n",
    "    model: nn.Module,\n",
    "    tokenizer: PreTrainedTokenizerBase,\n",
    "    training_samples: Sequence[SteeringVectorTrainingSample | tuple[str, str]],\n",
    "    layers: list[int] | None = None,\n",
    "    layer_type: LayerType = \"decoder_block\",\n",
    "    layer_config: ModelLayerConfig | None = None,\n",
    "    move_to_cpu: bool = False,\n",
    "    read_token_index: int | Callable[[str], int] = -1,\n",
    "    show_progress: bool = False,\n",
    "    aggregator: Aggregator = mean_aggregator(),\n",
    "    batch_size: int = 1,\n",
    "    tqdm_desc: str = \"Training steering vector\",\n",
    ") -> SteeringVector:\n",
    "    \"\"\"\n",
    "    Train a steering vector for the given model.\n",
    "\n",
    "    Args:\n",
    "        model: The model to train the steering vector for\n",
    "        tokenizer: The tokenizer to use\n",
    "        training_samples: A list of training samples, where each sample is a tuple of\n",
    "            (positive_str, negative_str). The steering vector approximate the\n",
    "            difference between the positive prompt and negative prompt activations.\n",
    "        layers: A list of layer numbers to train the steering vector on. If None, train\n",
    "            on all layers.\n",
    "        layer_type: The type of layer to train the steering vector on. Default is\n",
    "            \"decoder_block\".\n",
    "        layer_config: A dictionary mapping layer types to layer matching functions.\n",
    "            If not provided, this will be inferred automatically.\n",
    "        move_to_cpu: If True, move the activations to the CPU before training. Default False.\n",
    "        read_token_index: The index of the token to read the activations from. Default -1, meaning final token.\n",
    "        show_progress: If True, show a progress bar. Default False.\n",
    "        aggregator: A function that takes the positive and negative activations for a\n",
    "            layer and returns a single vector. Default is mean_aggregator.\n",
    "    \"\"\"\n",
    "    pos_acts, neg_acts = extract_activations(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        training_samples,\n",
    "        layers=layers,\n",
    "        layer_type=layer_type,\n",
    "        layer_config=layer_config,\n",
    "        move_to_cpu=move_to_cpu,\n",
    "        read_token_index=read_token_index,\n",
    "        show_progress=show_progress,\n",
    "        batch_size=batch_size,\n",
    "        tqdm_desc=tqdm_desc,\n",
    "    )\n",
    "\n",
    "    # concept erasure\n",
    "    \n",
    "    # get whether response is A\n",
    "    labels = []\n",
    "    for (pos, neg) in training_samples:\n",
    "        if pos.endswith(\"A)\"):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    # Print fraction of A's\n",
    "    print(sum(labels) / len(labels))\n",
    "\n",
    "    for layer in pos_acts.keys():\n",
    "        pos_act = pos_acts[layer]\n",
    "        neg_act = neg_acts[layer]\n",
    "        pos_act_batched = torch.stack(pos_act, dim=0)\n",
    "        neg_act_batched = torch.stack(neg_act, dim=0)\n",
    "\n",
    "        X = torch.cat([pos_act_batched, neg_act_batched], dim=0)\n",
    "\n",
    "        eraser = LeaceEraser.fit(pos_act_batched, neg_act_batched)\n",
    "    \n",
    "\n",
    "    layer_activations = aggregate_activations(pos_acts, neg_acts, aggregator)\n",
    "    return SteeringVector(layer_activations, layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/ml_workspace/repepo/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/daniel/ml_workspace/repepo/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Run experiment\n",
    "\n",
    "from repepo.steering.utils.helpers import make_dataset\n",
    "\n",
    "train_split = \"0%:50%\"\n",
    "dataset_name = \"believes-in-gun-rights\"\n",
    "test_split = \"50%:100%\"\n",
    "\n",
    "train_dataset = make_dataset(dataset_name, train_split)\n",
    "model, tokenizer = get_model_and_tokenizer(\"meta-llama/Llama-2-7b-chat-hf\", load_in_8bit=True)\n",
    "formatter = LlamaChatFormatter()\n",
    "pipeline = Pipeline(model, tokenizer, formatter)\n",
    "steering_vector_training_data = build_steering_vector_training_data(\n",
    "    pipeline, train_dataset\n",
    ")\n",
    "layer = 13\n",
    "\n",
    "\n",
    "pos_acts, neg_acts = extract_activations(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    steering_vector_training_data,\n",
    "    layers=[layer],\n",
    "    read_token_index=-2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repepo.paper.utils import PersonaCrossSteeringExperimentResult\n",
    "from repepo.paper.utils import (\n",
    "    load_persona_cross_steering_experiment_result,\n",
    "    get_steering_vector\n",
    ")\n",
    "\n",
    "selected_datasets = [\n",
    "    # 'politically-conservative',\n",
    "    'believes-in-gun-rights',\n",
    "    # 'myopic-reward',\n",
    "    # 'subscribes-to-moral-nihilism',\n",
    "    # 'subscribes-to-Hinduism'\n",
    "]\n",
    "\n",
    "dataset_steering_vectors = {}\n",
    "for dataset in selected_datasets:\n",
    "    print(dataset)\n",
    "    result = load_persona_cross_steering_experiment_result(dataset)\n",
    "    steering_vector = get_steering_vector(result)\n",
    "    dataset_steering_vectors[dataset] = steering_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SteeringVector(layer_activations={13: tensor([ 0.0140,  0.0134, -0.0027,  ..., -0.0186, -0.0241, -0.0150],\n",
       "       device='cuda:0', dtype=torch.float16)}, layer_type='decoder_block')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_steering_vectors['politically-conservative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politically-conservative\n",
      "tensor(0.1105, device='cuda:0', dtype=torch.float16)\n",
      "believes-in-gun-rights\n",
      "tensor(0.0062, device='cuda:0', dtype=torch.float16)\n",
      "myopic-reward\n",
      "tensor(0.0146, device='cuda:0', dtype=torch.float16)\n",
      "subscribes-to-moral-nihilism\n",
      "tensor(0.0956, device='cuda:0', dtype=torch.float16)\n",
      "subscribes-to-Hinduism\n",
      "tensor(0.0275, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity\n",
    "from torch.nn.functional import cosine_similarity\n",
    "for dataset, steering_vector in dataset_steering_vectors.items():\n",
    "    print(dataset)\n",
    "    print(\n",
    "        cosine_similarity(\n",
    "            ab_steering_vector.layer_activations[13], \n",
    "            steering_vector.layer_activations[13],\n",
    "            dim = -1\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
